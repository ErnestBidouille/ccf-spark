language: python
python:
  - "3.8"
sudo: false
addons:
  apt:
    packages:
      - axel
env:
    global:
        - SPARK_HOME=/tmp/spark-3.0.1-bin-hadoop2.7
before_install:
  - export PATH=$HOME/.local/bin:$PATH
install:
  - "[ -f spark ] || mkdir spark && cd spark && axel http://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz && cd .."
  - "tar -xf ./spark/spark-3.0.0-bin-hadoop2.7.tgz"
  - "export SPARK_HOME=`pwd`/spark-3.0.0-bin-hadoop2.7"
  - echo "spark.yarn.jars=$SPARK_HOME/jars/*.jar" > $SPARK_HOME/conf/spark-defaults.conf
  - pip install -r requirements-dev.txt
  - pip install .
script: python -m pytest